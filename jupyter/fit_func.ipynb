{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple example for performing symbolic regression for a set of points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nesymres.architectures.model import Model\n",
    "from nesymres.utils import load_metadata_hdf5\n",
    "from nesymres.dclasses import FitParams, NNEquation, BFGSParams\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "import torch\n",
    "from sympy import lambdify\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'config': {'max_len': 20, 'positive': True, 'env_name': 'eqlearn', 'operators': 'add:10,mul:10,sub:5,div:5,sqrt:4,pow2:4,pow3:2,pow4:1,pow5:1,ln:4,exp:4,sin:4,cos:4,tan:4,asin:2', 'max_ops': 5, 'int_base': 10, 'precision': 10, 'rewrite_functions': '', 'variables': ['x_1', 'x_2', 'x_3'], 'eos_index': 1, 'pad_index': 0}, 'total_coefficients': ['cm_0', 'cm_1', 'cm_2', 'cm_3', 'cm_4', 'cm_5', 'cm_6', 'cm_7', 'cm_8', 'cm_9', 'cm_10', 'cm_11', 'cm_12', 'cm_13', 'cm_14', 'cm_15', 'cm_16', 'cm_17', 'cm_18', 'cm_19', 'cm_20', 'cm_21', 'cm_22', 'cm_23', 'cm_24', 'cm_25', 'cm_26', 'cm_27', 'cm_28', 'cm_29', 'cm_30', 'cm_31', 'cm_32', 'cm_33', 'cm_34', 'cm_35', 'cm_36', 'cm_37', 'cm_38', 'cm_39', 'ca_0', 'ca_1', 'ca_2', 'ca_3', 'ca_4', 'ca_5', 'ca_6', 'ca_7', 'ca_8', 'ca_9', 'ca_10', 'ca_11', 'ca_12', 'ca_13', 'ca_14', 'ca_15', 'ca_16', 'ca_17', 'ca_18', 'ca_19', 'ca_20', 'ca_21', 'ca_22', 'ca_23', 'ca_24', 'ca_25', 'ca_26', 'ca_27', 'ca_28', 'ca_29', 'ca_30', 'ca_31', 'ca_32', 'ca_33', 'ca_34', 'ca_35', 'ca_36', 'ca_37', 'ca_38', 'ca_39'], 'total_variables': ['x_1', 'x_2', 'x_3'], 'word2id': {'x_1': 4, 'x_2': 5, 'x_3': 6, 'abs': 7, 'acos': 8, 'add': 9, 'asin': 10, 'atan': 11, 'cos': 12, 'cosh': 13, 'coth': 14, 'div': 15, 'exp': 16, 'ln': 17, 'mul': 18, 'pow': 19, 'sin': 20, 'sinh': 21, 'sqrt': 22, 'tan': 23, 'tanh': 24, '-3': 25, '-2': 26, '-1': 27, '0': 28, '1': 29, '2': 30, '3': 31, '4': 32, '5': 33, 'P': 0, 'S': 1, 'F': 2, 'c': 3}, 'id2word': {'4': 'x_1', '5': 'x_2', '6': 'x_3', '7': 'abs', '8': 'acos', '9': 'add', '10': 'asin', '11': 'atan', '12': 'cos', '13': 'cosh', '14': 'coth', '15': 'div', '16': 'exp', '17': 'ln', '18': 'mul', '19': 'pow', '20': 'sin', '21': 'sinh', '22': 'sqrt', '23': 'tan', '24': 'tanh', '25': '-3', '26': '-2', '27': '-1', '28': '0', '29': '1', '30': '2', '31': '3', '32': '4', '33': '5', '1': 'S', '2': 'F', '3': 'c'}, 'una_ops': ['asin', 'cos', 'exp', 'ln', 'pow2', 'pow3', 'pow4', 'pow5', 'sin', 'sqrt', 'tan'], 'bin_ops': ['asin', 'cos', 'exp', 'ln', 'pow2', 'pow3', 'pow4', 'pow5', 'sin', 'sqrt', 'tan'], 'rewrite_functions': [], 'total_number_of_eqs': 200, 'eqs_per_hdf': 200, 'generator_details': {'max_len': 20, 'operators': 'add:10,mul:10,sub:5,div:5,sqrt:4,pow2:4,pow3:2,pow4:1,pow5:1,ln:4,exp:4,sin:4,cos:4,tan:4,asin:2', 'max_ops': 5, 'rewrite_functions': '', 'variables': ['x_1', 'x_2', 'x_3'], 'eos_index': 1, 'pad_index': 0}, 'unique_index': None}\n"
     ]
    }
   ],
   "source": [
    "## Load equation configuration and architecture configuration\n",
    "import omegaconf\n",
    "with open('100M/eq_setting.json', 'r') as json_file:\n",
    "  eq_setting = json.load(json_file)\n",
    "print(eq_setting)\n",
    "\n",
    "cfg = omegaconf.OmegaConf.load(\"100M/config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up BFGS load rom the hydra config yaml\n",
    "bfgs = BFGSParams(\n",
    "        activated= cfg.inference.bfgs.activated,\n",
    "        n_restarts=cfg.inference.bfgs.n_restarts,\n",
    "        add_coefficients_if_not_existing=cfg.inference.bfgs.add_coefficients_if_not_existing,\n",
    "        normalization_o=cfg.inference.bfgs.normalization_o,\n",
    "        idx_remove=cfg.inference.bfgs.idx_remove,\n",
    "        normalization_type=cfg.inference.bfgs.normalization_type,\n",
    "        stop_time=cfg.inference.bfgs.stop_time,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_fit = FitParams(word2id=eq_setting[\"word2id\"], \n",
    "                            id2word={int(k): v for k,v in eq_setting[\"id2word\"].items()}, \n",
    "                            una_ops=eq_setting[\"una_ops\"], \n",
    "                            bin_ops=eq_setting[\"bin_ops\"], \n",
    "                            total_variables=list(eq_setting[\"total_variables\"]),  \n",
    "                            total_coefficients=list(eq_setting[\"total_coefficients\"]),\n",
    "                            rewrite_functions=list(eq_setting[\"rewrite_functions\"]),\n",
    "                            bfgs=bfgs,\n",
    "                            beam_size=5#cfg.inference.beam_size #This parameter is a tradeoff between accuracy and fitting time\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = \"../weights/100M.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.3.3 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../weights/100M.ckpt`\n"
     ]
    }
   ],
   "source": [
    "## Load architecture, set into eval mode, and pass the config parameters\n",
    "model = Model.load_from_checkpoint(weights_path, cfg=cfg.architecture)\n",
    "model.eval()\n",
    "if torch.cuda.is_available(): \n",
    "  model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitfunc = partial(model.fitfunc, cfg_params=params_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create points from an equation\n",
    "number_of_points = 500\n",
    "n_variables = 1\n",
    "\n",
    "#To get best results make sure that your support inside the max and mix support\n",
    "max_supp = cfg.dataset_train.fun_support[\"max\"] \n",
    "min_supp = cfg.dataset_train.fun_support[\"min\"]\n",
    "X = torch.rand(number_of_points,len(list(eq_setting[\"total_variables\"])))*(max_supp-min_supp)+min_supp\n",
    "X[:,n_variables:] = 0\n",
    "target_eq = \"x_1*sin(x_1)\" #Use x_1,x_2 and x_3 as independent variables\n",
    "X_dict = {x:X[:,idx].cpu() for idx, x in enumerate(eq_setting[\"total_variables\"])} \n",
    "y = lambdify(\",\".join(eq_setting[\"total_variables\"]), target_eq)(**X_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  torch.Size([500, 3])\n",
      "y shape:  torch.Size([500])\n"
     ]
    }
   ],
   "source": [
    "print(\"X shape: \", X.shape)\n",
    "print(\"y shape: \", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'all_bfgs_preds': ['((x_1)*(sin(x_1)))', '((x_1)*((cos(x_1))*(tan(x_1))))', 'x_1*(-2.4124309458153e-10*x_1 + sin(x_1))', 'x_1*(-1.45303738201554e-9*(x_1 + 0.372434186667584)**2 + sin(x_1))', 'x_1*(-6.5095906123594e-11*x_1**2 + sin(x_1))'], 'all_bfgs_loss': [0.0, 5.058057e-14, 4.6386506e-18, 3.4721214e-13, 1.5486613e-16], 'best_bfgs_preds': ['((x_1)*(sin(x_1)))'], 'best_bfgs_loss': [0.0]}\n",
      "18.853568077087402\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "output = fitfunc(X,y)\n",
    "print(output)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all_bfgs_preds': ['((x_1)*(sin(x_1)))',\n",
       "  '((x_1)*((cos(x_1))*(tan(x_1))))',\n",
       "  'x_1*(-2.4124309458153e-10*x_1 + sin(x_1))',\n",
       "  'x_1*(-1.45303738201554e-9*(x_1 + 0.372434186667584)**2 + sin(x_1))',\n",
       "  'x_1*(-6.5095906123594e-11*x_1**2 + sin(x_1))'],\n",
       " 'all_bfgs_loss': [0.0,\n",
       "  5.058057e-14,\n",
       "  4.6386506e-18,\n",
       "  3.4721214e-13,\n",
       "  1.5486613e-16],\n",
       " 'best_bfgs_preds': ['((x_1)*(sin(x_1)))'],\n",
       " 'best_bfgs_loss': [0.0]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ProjectAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
