{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139234b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import multiprocessing\n",
    "multiprocessing.set_start_method(\"spawn\")\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../..\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d755376f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from collections import Counter\n",
    "from tqdm.auto import tqdm\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import os\n",
    "from utils import (\n",
    "    same_recons, get_topk_acc, get_layer_names,\n",
    "    evaluate_performance, Logger, prepare_encoders, get_layer_names_new\n",
    ")\n",
    "from intervention_utils import intervension\n",
    "from IterativePatching import initialize_model, prepare_inputs\n",
    "import glob\n",
    "def load_dataset(operation, base_path=None, eval=\"TRAIN\"):\n",
    "    if base_path is None:\n",
    "        path = os.path.join(\"data\", \"Arco\", \"CircuitFinding\")\n",
    "    else:\n",
    "        path = os.path.join(base_path, \"data\", \"Arco\", \"CircuitFinding\")\n",
    "    abs_path = os.path.abspath(path)\n",
    "\n",
    "    file_path = glob.glob(f\"{abs_path}/CD_{eval}_{operation}_*.npy\")[0]\n",
    "    data = np.load(file_path, allow_pickle=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4d36c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"../../circuit_config_2.json\", \"r\") as f:\n",
    "    configs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed2ff85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_topk_dataset(ranks, datapoints, top1=0, top2=0, top3=0, seed=42):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    ranks = np.array(ranks)\n",
    "    datapoints = np.array(datapoints, dtype=object)\n",
    "\n",
    "    idx_top1 = np.where(ranks == 1)[0]\n",
    "    idx_top2 = np.where(ranks == 2)[0]\n",
    "    idx_top3 = np.where(ranks == 3)[0]\n",
    "\n",
    "    if len(idx_top1) < top1 or len(idx_top2) < top2 or len(idx_top3) < top3:\n",
    "        raise ValueError(\"Not enough samples in one or more top-k categories.\")\n",
    "\n",
    "    selected_idx_1 = np.random.choice(idx_top1, top1, replace=False)\n",
    "    selected_idx_2 = np.random.choice(idx_top2, top2, replace=False)\n",
    "    selected_idx_3 = np.random.choice(idx_top3, top3, replace=False)\n",
    "\n",
    "    all_selected_idx = np.concatenate([selected_idx_1, selected_idx_2, selected_idx_3])\n",
    "    subset = datapoints[all_selected_idx]\n",
    "    return all_selected_idx.tolist(), subset.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f389cfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ITERATVIE\n",
    "intervention_class, model = initialize_model(base_path=\"../..\")\n",
    "full_range = set(range(0, 117))  # 0 to 117 inclusive\n",
    "EVAL = \"TRAIN\"\n",
    "\n",
    "counter = 0\n",
    "for config in configs[:]:\n",
    "    OPERATION = config[\"operation\"]\n",
    "    PATCH_TYPE = config[\"patch_type\"] # mean or resample\n",
    "    CTR_TOKEN = config[\"CTR_token\"]\n",
    "    CIRCUIT = config[\"circuit\"]\n",
    "    CTR = config[\"CTR\"]\n",
    "\n",
    "    MAX_SAMPLES = 500\n",
    "    TYPE_SUBSET = \"correct\"\n",
    "    if CTR:\n",
    "        continue\n",
    "\n",
    "    layer_names = get_layer_names_new()\n",
    "    datapoints = load_dataset(OPERATION, base_path=\"../..\", eval=EVAL)\n",
    "    datapoints = np.array(datapoints, dtype=object)\n",
    "    if PATCH_TYPE == \"mean\":\n",
    "        mean_patches = np.load(\"../../data/Arco/MeanPatching/mean_patching_10000.npy\", allow_pickle=True).item()\n",
    "    elif PATCH_TYPE == \"resample\":\n",
    "        n = 100 if EVAL == \"TRAIN\" else 400 if OPERATION != \"log\" else 209\n",
    "        data_name = f\"../../data/Arco/ResamplePatching/cached_values_{n}_{OPERATION}_{CTR_TOKEN}_{EVAL}.npz\"\n",
    "        if CTR:\n",
    "            print(\"Using CTR ONLY\")\n",
    "            mean_patches = np.load(data_name, allow_pickle=True)[\"resample_patch_CTR\"]\n",
    "        else:\n",
    "            mean_patches = np.load(data_name, allow_pickle=True)[\"resample_patch_mean\"]\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    Xs, ys, equations, eqs_untill_target = prepare_inputs(intervention_class, \n",
    "                                                          datapoints, \n",
    "                                                          200, \n",
    "                                                          max_samples=MAX_SAMPLES)\n",
    "    patch_type = PATCH_TYPE\n",
    "\n",
    "    \n",
    "    # Baseline\n",
    "    encoders = prepare_encoders(layer_names, [], mean_patches, patch_type, model, Xs, ys)\n",
    "    ranks, counter, model_logit_score = evaluate_performance(model,\n",
    "                                                         intervention_class,\n",
    "                                                         encoders,\n",
    "                                                         equations,\n",
    "                                                         eqs_untill_target,\n",
    "                                                         OPERATION,\n",
    "                                                         return_activation=True)\n",
    "    model_top1 = get_topk_acc(counter, 1)\n",
    "    model_top2 = get_topk_acc(counter, 2)\n",
    "    model_top3 = get_topk_acc(counter, 3)\n",
    "    print(f\"model:              Top-1: {model_top1:.3f}, Top-2: {model_top2:.3f}, Top-3: {model_top3:.3f}, logit score: {model_logit_score.mean():.3f}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    # performance of model with circuit only\n",
    "    excluded = full_range - set(CIRCUIT)\n",
    "\n",
    "    encoders = prepare_encoders(layer_names, excluded, mean_patches, patch_type, model, Xs, ys)\n",
    "    ranks, counter, circuit_logit_score = evaluate_performance(model,\n",
    "                                                intervention_class,\n",
    "                                                encoders,\n",
    "                                                equations,\n",
    "                                                eqs_untill_target,\n",
    "                                                OPERATION,\n",
    "                                                return_activation=True)\n",
    "\n",
    "    circuit_top1 = get_topk_acc(counter, 1)\n",
    "    circuit_top2 = get_topk_acc(counter, 2)\n",
    "    circuit_top3 = get_topk_acc(counter, 3)\n",
    "    print(f\"Circuit:            Top-1: {circuit_top1:.3f}, Top-2: {circuit_top2:.3f}, Top-3: {circuit_top3:.3f}, logit score: {circuit_logit_score.mean():.3f}\")\n",
    "    \n",
    "    encoders = prepare_encoders(layer_names, full_range, mean_patches, patch_type, model, Xs, ys)\n",
    "    ranks, counter, MC_logit_score = evaluate_performance(model,\n",
    "                                                         intervention_class,\n",
    "                                                         encoders,\n",
    "                                                         equations,\n",
    "                                                         eqs_untill_target,\n",
    "                                                         OPERATION,\n",
    "                                                         return_activation=True)\n",
    "    \n",
    "    MC_top1 = get_topk_acc(counter, 1)\n",
    "    MC_top2 = get_topk_acc(counter, 2)\n",
    "    MC_top3 = get_topk_acc(counter, 3)\n",
    "    print(f\"model compliment:   Top-1: {MC_top1:.3f}, Top-2: {MC_top2:.3f}, Top-3: {MC_top3:.3f}, logit score: {MC_logit_score.mean():.3f}\")\n",
    "    \n",
    "    # performance of model with circuit only\n",
    "    excluded = full_range - set(CIRCUIT)\n",
    "    encoders = prepare_encoders(layer_names, CIRCUIT, mean_patches, patch_type, model, Xs, ys)\n",
    "    ranks, counter, CC_logit_score = evaluate_performance(model,\n",
    "                                                intervention_class,\n",
    "                                                encoders,\n",
    "                                                equations,\n",
    "                                                eqs_untill_target,\n",
    "                                                OPERATION,\n",
    "                                                return_activation=True)\n",
    "    \n",
    "    CC_top1 = get_topk_acc(counter, 1)\n",
    "    CC_top2 = get_topk_acc(counter, 2)\n",
    "    CC_top3 = get_topk_acc(counter, 3)\n",
    "    print(f\"Circuit compliment: Top-1: {CC_top1:.3f}, Top-2: {CC_top2:.3f}, Top-3: {CC_top3:.3f}, logit score: {CC_logit_score.mean():.3f}\")\n",
    "    print(f\"{OPERATION} {PATCH_TYPE.capitalize()[0]}{config['Evaluation_type'].capitalize()[0]} & {len(CIRCUIT)} & {circuit_top1:.3f} & {circuit_top2:.3f} & {circuit_top3:.3f} & {circuit_logit_score.mean():.3f} && {CC_top3:.3f} & {CC_logit_score.mean():.3f} & -  & - \")\n",
    "print(counter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ProjectAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
